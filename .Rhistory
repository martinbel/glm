OR[row.names(OR) == 'Age', ]
rm(list = ls(all=TRUE))
# Saco notacion cientifica
options(scipen=666)
# setwd(path)
rm(list = ls(all=TRUE))
d = read.table("Adult.txt", sep="\t", header=TRUE)
### 1.1.1
# Separe las poblaciones en entrenamiento y validación en forma aleatoria.
# Indique que cantidad de casos quedaron para cada ambiente.
library(caret)
td <- sapply(d, class)
# Me fijo los valores unicos de cada variable
ln <- apply(d, 2, function(x) length(unique(x)))
# Si tiene más de 16 valores la convierto como factor,
# después será convertida a categorica
fact = names(ln[ln < 17])
d <- d[order(d$Clase, decreasing=TRUE), ]
# Defino como factor a las nominales
for(j in fact) d[, j] <- as.factor(as.character(d[, j]))
d$Clase <- ifelse(d$Clase == 0, 'BAJO', 'ALTO')
d$Clase <- factor(d$Clase, levels=c("ALTO", 'BAJO'))
td <- sapply(d, class)
### Calculo cuantos NA hay por columna
na <- apply(d, 2, function(x) sum(is.na(x)))
print('variables con NAs')
na[na !=0]
# Los NAs estan en variables categoricas, agrego una categoria y listo
# Para eso defino a la funcion addNA
# d$WorkClass <- addNA(d$WorkClass)
# d$Occupation <- addNA(d$Occupation)
if(sum(is.na(d)) != 0)
stop('Todavia hay NAs')
# Filtro registros con NAs
# Usar si no usas la funcion anterior
d <- d[complete.cases(d), ]
### Split en training y testing (sampleo estratificado por la clase)
# Necesita al paquete caret
set.seed(123)
in_train <- createDataPartition(d$Clase, p=0.7, list=F)
train <- d[in_train, ]
test <- d[-in_train, ]
print(dim(train))
print(dim(test))
# 1.1.2  Formule el mejor modelo posible de regresión logística
library(leaps)
# Genero dos modelos el nulo y el completo
null <- glm(formula=Clase ~ 1, data=train, family='binomial')
full <- glm(formula=Clase ~ ., data=train, family='binomial')
# Foward
fwd <- step(null, scope=list(lower=null, upper=full), direction="forward", na.action='na.omit')
# Stepwise
step <- step(null, scope=list(lower=null, upper=full), direction="both", na.action='na.omit')
# Backward
back <- step(full, data=Housing, direction="backward", na.action='na.omit')
# Grabo lo anterior
# Se puede leer de nuevo usando load('glm.RData')
save.image('glm.RData')
library(pROC)
library(caret)
plot_rocs <- function(train, test, model, titulo='ROC stepwise'){
# Genera las predicciones de entrenamiento y testeo
probs_train <- predict(model, newdata=train, type="response")
probs_test <- predict(model, newdata=test, type="response")
par(mfrow=c(1, 2))
# Grafica la ROC de training en el cuadrante izquierdo
roc_train <- plot.roc(Clase ~ probs_train, data=train,
main=paste0(titulo, ' train'), percent=TRUE,  print.auc=TRUE,
thresholds="best", print.thres='best', col="#1c61b6")
# Grafica la ROC de testing en el cuadrante derecho
roc_test <- plot.roc(Clase ~ probs_test, data=test,
main=paste0(titulo, ' test'), percent=TRUE,  print.auc=TRUE,
thresholds="best", print.thres='best', col="#008600")
par(mfrow=c(1, 1))
# Devuelve una lista con los siguientes elementos
list(roc_train=roc_train, roc_test=roc_test,
probs_train=probs_train, probs_test=probs_test)
}
# 1.1.3 Calcular el AUC y las ROC en train y testing
roc_fwd <- plot_rocs(train, test, fwd, "ROC Foward")
roc_step <- plot_rocs(train, test, step, "ROC Stepwise")
roc_back <- plot_rocs(train, test, back, "ROC Backward")
# Stepwise y foward encuentran los mismos modelos (la formula es la misma)
identical(fwd$formula, step$formula)
# backward encuentra otra formula
identical(back$formula, step$formula)
# Genero una lista con todos los modelos
modelos <- list(fwd=fwd, step=step, back=back)
# Uso "[[" para extraer elementos por su nombre
# Formula de cada modelo
lapply(modelos, '[[', 'formula')
# Que variables fueron entrando y como vario el AIC
lapply(modelos, '[[', 'anova')
# 1.1.4  Selecciones el 10% de los trabajadores en el ambiente de validación de acuerdo a la siguiente lógica.
# Entregue los resultados indicados:
# -	Al azar e indique la cantidad de trabajadores que llegaron a superar los 50.000 dólares anuales.
# -	Utilizando el modelo desarrollado en el punto 1.1.2 e
# indique la cantidad de trabajadores que llegaron a superar los 50.000 dólares anuales.
set.seed(123)
in_validation <- createDataPartition(test$Clase, p=0.1, list=F)
validation <- test[in_validation, ]
# Porcentaje de clase = ALTO al azar en el 10%
clase_10pct <- sum(validation$Clase == "ALTO")
probs <- as.vector(roc_fwd$probs_test)
probs <- 1 - probs
quantile(probs, seq(0, 1, 0.1))
# probs > al percentil 90
# Es el 10% con mejor probabilidad
sum(probs > 0.7358215446639233548)
pred <- ifelse(probs > 0.7358215446639233548, "ALTO", "BAJO")
tbl <- table(pred, test$Clase)
# LIFT
lift <- tbl[1,1] / clase_10pct
print(lift)
metricas <- function(tbl){
sensitividad <- tbl[1,1] / sum(tbl[,1])
especificidad <- tbl[2,2] / sum(tbl[,2])
accuracy <- sum(diag(tbl)) / sum(tbl)
lift <- tbl[1,1] / sum(validation$Clase == "ALTO")
data.frame(sensitividad=sensitividad, especificidad=especificidad, accuracy=accuracy, lift=lift)
}
metricas(tbl)
# 1.1.5	Calcular y/o obtener los siguientes resultados:
# a)	Indicar en cuanto sería el impacto en modificar una unidad de por lo menos una variable continua del modelo.
# b)	Indicar si hay puntos incluyentes con COOK.
# c)	Indicar que método de selección de variables se utilizó y explicar su funcionamiento.
# d)	Mostrar el estadístico de Hosmer-Lemeshow en el último paso del modelo.
# a)
summary(fwd)
OR <- exp(data.frame(coef(fwd)))
# Variable Continua capital_loss
# Ante un aumento en una unidad en la variable X, se espera que aumente sus odds en:
OR[row.names(OR) == 'Age', ]
perf <- performance(probs, "lift", "rpp")
library(ROCR)
perf <- performance(probs, "lift", "rpp")
?performance
table(probs)
table(pred)
perf <- performance(pred, "lift", "rpp")
pred <- prediction(pred, test$Clase)
test$Clase
as.numeric(test$Clase)
pred <- prediction(as.numeric(pred), as.numeric(test$Clase))
data(ROCR.simple)
head(ROCR.simple)
pred <- prediction(probs, test$Clase)
perf <- performance(pred, "lift", "rpp")
plot(perf, main="lift curve", colorize=T)
install.packages(gains)
install.packages('gains')
library('gains')
gains.rf<-with(subset(ciaScores,train==0),
gains(actual=CellPhonesPP, predicted=PredRF, optimal=TRUE))
gains.rf
plot(gains.rf)
table(pred)
pred <- ifelse(probs > 0.7358215446639233548, "ALTO", "BAJO")
tbl <- table(pred, test$Clase)
tbl
gains.fwd <- with(test, gains(actual=Clase, predicted=pred, optimal=TRUE))
table(pred)
table(test$Clase)
gains.fwd <- gains(actual=test$Clase, predicted=pred, optimal=TRUE)
?gains
pred
test$Clase
length(test$Clase)
length(pred)
pred <- prediction(probs, test$Clase)
perf <- performance(pred, "lift", "tpr", "rpp")
pred <- prediction(probs, test$Clase)
perf <- performance(pred, "lift", "tpr")
plot(perf, main="lift curve", colorize=T)
?performance
perf <- performance(pred, "lift")
plot(perf, main="lift curve", colorize=T)
perf <- performance(pred, "lift", "lift")
plot(perf, main="lift curve", colorize=T)
perf <- performance(pred, "lift", "auc")
perf <- performance(pred, measure="lift", x.measure="rpp")
plot(perf, main="lift curve", colorize=T)
probs <- as.vector(roc_fwd$probs_test)
pred <- ifelse(probs > 0.7358215446639233548, "ALTO", "BAJO")
perf <- performance(pred, measure="lift", x.measure="rpp")
?prediction
perf <- performance(pred, measure="lift", x.measure="rpp")
pred <- prediction(pred, test$Clase)
pred <- prediction(probs, test$Clase)
perf <- performance(pred, measure="lift", x.measure="rpp")
plot(perf, main="lift curve", colorize=T)
quantile(probs, seq(0,1,0.1))
probs <- 1 - probs
pred <- prediction(probs, test$Clase)
perf <- performance(pred, measure="lift", x.measure="rpp")
plot(perf, main="lift curve", colorize=T)
str(pred)
perf <- performance(pred, measure="tpr", x.measure="fpr")
plot(perf, main="ROC Curve", colorize=T)
table(pred)
probs <- as.vector(roc_fwd$probs_test)
quantile(probs, seq(0, 1, 0.1))
pred <- prediction(probs, test$Clase)
perf <- performance(pred, measure="tpr", x.measure="fpr")
plot(perf, main="ROC Curve", colorize=T)
lift_pred <- prediction(probs, test$Clase)
perf_lift <- performance(lift_pred, measure="lift", x.measure="rpp")
perf_lift
str(perf_lift)
plot(perf_lift, main="lift curve", colorize=T)
table(test$clase)
table(test$Clase)
2295/ 6920
nrow(d)
nrow(train)
nrow(test)
nrow(test) * 0.1
length(in_validation)
clase_10pct <- sum(validation$Clase == "ALTO")
clase_10pct
probs <- as.vector(roc_fwd$probs_test)
length(v)
length(roc_fwd$probs_test)
dim(test)
quantile(probs, seq(0, 1, 0.1))
probs <- as.vector(roc_step$probs_test)
quantile(probs, seq(0, 1, 0.1))
probs <- as.vector(roc_fwd$probs_test)
quantile(probs, seq(0, 1, 0.1))
sum(probs > 0.7358215446639233548)
qt_90 <- quantile(probs, 0.9)
qt_90
qt_90[[1]]
sum(probs > qt_90[[1]])
pred <- ifelse(probs > qt_90[[1]], "ALTO", "BAJO")
tbl <- table(pred, test$Clase)
tbl
pred <- ifelse(probs > qt_90[[1]],"BAJO", "ALTO")
tbl <- table(pred, test$Clase)
tbl
quantile(probs, seq(0, 1, 0.1))
pred <- ifelse(probs < 0.2641784553360767007213, "ALTO", "BAJO")
tbl <- table(pred, test$Clase)
tbl
lift <- tbl[1,1] / clase_10pct
print(lift)
pred <- factor(ifelse(probs < 0.2641784553360767007213, "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
tbl
lift <- tbl[1,1] / clase_10pct
print(lift)
metricas <- function(tbl){
sensitividad <- tbl[1,1] / sum(tbl[,1])
especificidad <- tbl[2,2] / sum(tbl[,2])
accuracy <- sum(diag(tbl)) / sum(tbl)
lift <- tbl[1,1] / sum(validation$Clase == "ALTO")
data.frame(sensitividad=sensitividad, especificidad=especificidad, accuracy=accuracy, lift=lift)
}
metricas(tbl)
pred <- prediction(probs, test$Clase)
perf <- performance(pred, measure="tpr", x.measure="fpr")
plot(perf, main="ROC Curve", colorize=T)
lift_pred <- prediction(probs, test$Clase)
perf_lift <- performance(lift_pred, measure="lift", x.measure="rpp")
plot(perf_lift, main="lift curve", colorize=T)
probs <- as.vector(roc_fwd$probs_test)
probs <- 1 - probs
quantile(probs, seq(0, 1, 0.1))
qt_90 <- quantile(probs, 0.9)
qt_90
sum(probs > qt_90[[1]])
pred <- factor(ifelse(probs < qt_90[[1]], "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
tbl
probs <- as.vector(roc_fwd$probs_test)
quantile(probs, seq(0, 1, 0.1))
qt_90 <- quantile(probs, 0.9)
sum(probs > qt_90[[1]])
pred <- factor(ifelse(probs < qt_90[[1]], "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
tbl
probs <- as.vector(roc_fwd$probs_test)
quantile(probs)
table(train$Clase)
probs <- as.vector(roc_fwd$probs_test)
probs <- 1 - probs
quantile(probs, seq(0, 1, 0.1))
qt_90 <- quantile(probs, 0.9)
# probs > al percentil 90
# Es el 10% con mejor probabilidad
sum(probs > qt_90[[1]])
pred <- factor(ifelse(probs > qt_90[[1]], "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
tbl
lift <- tbl[1,1] / clase_10pct
print(lift)
pred <- prediction(probs, test$Clase)
perf <- performance(pred, measure="tpr", x.measure="fpr")
plot(perf, main="ROC Curve", colorize=T)
levels(test$Clase)
levels(probs)
table(probs)
table(pred)
class(pred)
predict.glm
linkinv
?predict
ldose <- rep(0:5, 2)
numdead <- c(1, 4, 9, 13, 18, 20, 0, 2, 6, 10, 12, 16)
sex <- factor(rep(c("M", "F"), c(6, 6)))
SF <- cbind(numdead, numalive = 20-numdead)
budworm.lg <- glm(SF ~ sex*ldose, family = binomial)
summary(budworm.lg)
plot(c(1,32), c(0,1), type = "n", xlab = "dose",
ylab = "prob", log = "x")
text(2^ldose, numdead/20, as.character(sex))
ld <- seq(0, 5, 0.1)
lines(2^ld, predict(budworm.lg, data.frame(ldose = ld,
sex = factor(rep("M", length(ld)), levels = levels(sex))),
type = "response"))
lines(2^ld, predict(budworm.lg, data.frame(ldose = ld,
sex = factor(rep("F", length(ld)), levels = levels(sex))),
type = "response"))
predict(budworm.lg, data.frame(ldose = ld,
sex = factor(rep("M", length(ld)), levels = levels(sex))),
type = "response")
data.frame(ldose = ld, sex = factor(rep("M", length(ld)), levels = levels(sex)))
head(data.frame(ldose = ld, sex = factor(rep("M", length(ld)), levels = levels(sex))))
summary(budworm.lg)
newd=data.frame(ldose = ld, sex = factor(rep("M", length(ld)), levels = levels(sex)))
p = predict(budworm.lg, newd, type = "response")
p
levels(test$Clase)
levels(train$Clase)
levels(d$Clase)
probs <- predict(fwd, newdata=test, type="response")
probs <- as.vector(probs)
quantile(probs, seq(0, 1, 0.1))
probs <- predict(fwd, newdata=test, type="link")
quantile(probs, seq(0, 1, 0.1))
logit <- function(x) 1 / (1 + exp(-x))
probs <- logit(as.vector(probs))
probs
quantile(probs, seq(0, 1, 0.1))
probs <- predict(fwd, newdata=test, type="terms")
probs
str(probs)
probs <- predict(fwd, newdata=test, type="response")
probs
probs <- predict(fwd, newdata=test, type="response")
quantile(probs, seq(0, 1, 0.1))
quantile(probs, seq(0, 1, 0.1))
qt_90 <- quantile(probs, 0.9)
sum(probs > qt_90[[1]])
pred <- factor(ifelse(probs > qt_90[[1]], "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
tbl
probs <- predict(fwd, newdata=test, type="response")
probs <- 1 - probs
quantile(probs, seq(0, 1, 0.1))
qt_90 <- quantile(probs, 0.9)
sum(probs > qt_90[[1]])
pred <- factor(ifelse(probs > qt_90[[1]], "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
tbl
lift <- tbl[1,1] / clase_10pct
print(lift)
metricas <- function(tbl){
sensitividad <- tbl[1,1] / sum(tbl[,1])
especificidad <- tbl[2,2] / sum(tbl[,2])
accuracy <- sum(diag(tbl)) / sum(tbl)
lift <- tbl[1,1] / sum(validation$Clase == "ALTO")
data.frame(sensitividad=sensitividad, especificidad=especificidad, accuracy=accuracy, lift=lift)
}
metricas(tbl)
summary(fwd)
OR[row.names(OR) == 'Age', ]
library(ROCR)
pred <- prediction(probs, test$Clase)
perf <- performance(pred, measure="tpr", x.measure="fpr")
plot(perf, main="ROC Curve", colorize=T)
pred <- prediction(1-probs, test$Clase)
perf <- performance(pred, measure="tpr", x.measure="fpr")
plot(perf, main="ROC Curve", colorize=T)
lift_pred <- prediction(1-probs, test$Clase)
perf_lift <- performance(lift_pred, measure="lift", x.measure="rpp")
plot(perf_lift, main="lift curve", colorize=T)
d$Clase <- factor(ifelse(d$Clase == 1, 'ALTO', 'BAJO'), levels = c("yes", "no"))
table(d$Clase)
# Ejercicio de repaso - Regresion Logistica
rm(list = ls(all=TRUE))
# Saco notacion cientifica
options(scipen=666)
# setwd(path)
rm(list = ls(all=TRUE))
d = read.table("Adult.txt", sep="\t", header=TRUE)
### 1.1.1
# Separe las poblaciones en entrenamiento y validación en forma aleatoria.
# Indique que cantidad de casos quedaron para cada ambiente.
library(caret)
td <- sapply(d, class)
# Me fijo los valores unicos de cada variable
ln <- apply(d, 2, function(x) length(unique(x)))
# Si tiene más de 16 valores la convierto como factor,
# después será convertida a categorica
fact = names(ln[ln < 17])
d <- d[order(d$Clase, decreasing=TRUE), ]
# Defino como factor a las nominales
for(j in fact) d[, j] <- as.factor(as.character(d[, j]))
d$Clase <- factor(ifelse(d$Clase == 1, 'ALTO', 'BAJO'), levels = c("yes", "no"))
table(d$Clase)
# Ejercicio de repaso - Regresion Logistica
rm(list = ls(all=TRUE))
# Saco notacion cientifica
options(scipen=666)
# setwd(path)
rm(list = ls(all=TRUE))
d = read.table("Adult.txt", sep="\t", header=TRUE)
### 1.1.1
# Separe las poblaciones en entrenamiento y validación en forma aleatoria.
# Indique que cantidad de casos quedaron para cada ambiente.
library(caret)
td <- sapply(d, class)
# Me fijo los valores unicos de cada variable
ln <- apply(d, 2, function(x) length(unique(x)))
# Si tiene más de 16 valores la convierto como factor,
# después será convertida a categorica
fact = names(ln[ln < 17])
d <- d[order(d$Clase, decreasing=TRUE), ]
# Defino como factor a las nominales
for(j in fact) d[, j] <- as.factor(as.character(d[, j]))
d$Clase <- factor(ifelse(d$Clase == 1, 'ALTO', 'BAJO'), levels = c("ALTO", "BAJO"))
td <- sapply(d, class)
table(d$Clase)
na <- apply(d, 2, function(x) sum(is.na(x)))
print('variables con NAs')
na[na !=0]
d <- d[complete.cases(d), ]
set.seed(123)
in_train <- createDataPartition(d$Clase, p=0.7, list=F)
train <- d[in_train, ]
test <- d[-in_train, ]
print(dim(train))
print(dim(test))
library(leaps)
null <- glm(formula=Clase ~ 1, data=train, family='binomial')
full <- glm(formula=Clase ~ ., data=train, family='binomial')
fwd <- step(null, scope=list(lower=null, upper=full), direction="forward", na.action='na.omit')
library(pROC)
library(caret)
set.seed(123)
in_validation <- createDataPartition(test$Clase, p=0.1, list=F)
validation <- test[in_validation, ]
clase_10pct <- sum(validation$Clase == "ALTO")
probs <- predict(fwd, newdata=test, type="response")
quantile(probs, seq(0, 1, 0.1))
probs <- predict(fwd, newdata=test, type="response")
quantile(probs, seq(0, 1, 0.1))
sum(probs > qt_90[[1]])
qt_90 <- quantile(probs, 0.9)
sum(probs > qt_90[[1]])
quantile(probs, seq(0, 1, 0.1))
cuts <- quantile(probs, seq(0, 1, 0.1))
cut_off <- function(){
cut <- quantile(probs, seq(0, 1, 0.1))
pred <- factor(ifelse(probs > cut, "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
}
cut_off()
cut_off <- function(cut){
pred <- factor(ifelse(probs > cut, "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
}
lapply(cut, cut_off)
lapply(cut, cut_off)
pred <- factor(ifelse(probs > cut, "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
cut
rm(cut)
ct <- quantile(probs, seq(0, 1, 0.1))
lapply(ct, cut_off)
cut_off <- function(cut){
pred <- factor(ifelse((1 -probs) > cut, "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
tbl
}
lapply(ct, cut_off)
ct <- quantile(probs, seq(0, 1, 0.01))
lapply(ct, cut_off)
cut_off <- function(cut){
pred <- factor(ifelse((1 -probs) > cut, "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
sum(diag(tbl)) / sum(tbl)
}
sapply(ct, cut_off)
cut_off <- function(cut){
pred <- factor(ifelse( probs > cut, "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
sum(diag(tbl)) / sum(tbl)
}
sapply(ct, cut_off)
cut_off <- function(cut){
pred <- factor(ifelse(1-probs > cut, "ALTO", "BAJO"), levels=c('ALTO', 'BAJO'))
tbl <- table(pred, test$Clase)
sum(diag(tbl)) / sum(tbl)
}
sapply(ct, cut_off)
?performance
install_github("hadley/l1tf")
devtools::install_github("hadley/l1tf")
install_github
library(devtools)
install_github("hadley/l1tf")
